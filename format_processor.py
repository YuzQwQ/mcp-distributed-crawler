import json
import re
import os
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from datetime import datetime

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class FormatProcessor:
    """é€šç”¨æ ¼å¼å¤„ç†å™¨ï¼Œæ ¹æ®é…ç½®æ–‡ä»¶åŠ¨æ€ç”ŸæˆJSONå’ŒMarkdownæ ¼å¼"""
    
    def __init__(self, format_type: str = "dfd", config_file: str = None):
        if config_file is None:
            # é»˜è®¤ä½¿ç”¨DFDæ ¼å¼é…ç½®æ–‡ä»¶
            config_dir = os.path.join(os.path.dirname(__file__), "config")
            config_file = os.path.join(config_dir, "format_templates.json")
        
        self.config_file = Path(config_file)
        self.format_type = format_type
        self.templates = self._load_templates()
        
        # è·å–æŒ‡å®šæ ¼å¼çš„æ¨¡æ¿
        if format_type in self.templates:
            self.template = self.templates[format_type]
        else:
            logger.warning(f"æ ¼å¼ç±»å‹æœªæ‰¾åˆ°: {format_type}ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
            default_templates = self._get_default_template()
            self.templates.update(default_templates)
            self.template = default_templates["dfd"]
        
        self.format_name = self.template.get("format_name", "DFDçŸ¥è¯†åº“")
    
    def _load_templates(self) -> Dict:
        """åŠ è½½æ ¼å¼æ¨¡æ¿é…ç½®"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {self.config_file}ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_template()
        except json.JSONDecodeError as e:
            logger.warning(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_template()
    
    def _get_default_template(self) -> Dict:
        """è¿”å›é»˜è®¤çš„DFDæ ¼å¼æ¨¡æ¿"""
        return {
            "dfd": {
                "format_name": "DFDçŸ¥è¯†åº“",
                "description": "æ•°æ®æµå›¾çŸ¥è¯†åº“çš„ç»“æ„åŒ–æ•°æ®æ ¼å¼",
                "version": "1.0.0",
                "json_structure": {
                    "metadata": {
                        "title": "string",
                        "source_url": "string",
                        "source_title": "string",
                        "crawl_time": "string"
                    },
                    "knowledge_categories": [
                        {"key": "dfd_concepts", "description": "DFDæ¦‚å¿µå®šä¹‰"},
                        {"key": "dfd_rules", "description": "DFDè§„åˆ™åº“"},
                        {"key": "dfd_patterns", "description": "DFDæ¨¡å¼åº“"},
                        {"key": "dfd_cases", "description": "DFDæ¡ˆä¾‹åº“"},
                        {"key": "dfd_nlp_mappings", "description": "DFDè‡ªç„¶è¯­è¨€æ˜ å°„"}
                    ]
                },
                "markdown_template": {
                    "header": {
                        "title": "# ğŸ“š {topic}çŸ¥è¯†åº“æå–ç»“æœï¼š{title}",
                        "metadata": [
                            "> æ¥æºï¼š[{title}]({source_url})",
                            "> æŠ“å–æ—¶é—´ï¼š{crawl_time_human}",
                            "> æå–æ–¹æ³•ï¼š{extraction_method}"
                        ]
                    },
                    "sections": [
                        {
                            "title": "## ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡",
                            "content": [
                                "- **æ¦‚å¿µå®šä¹‰**: {concepts_count} ä¸ª",
                                "- **è§„åˆ™æ¡ç›®**: {rules_count} ä¸ª",
                                "- **æ¨¡å¼æ¨¡æ¿**: {patterns_count} ä¸ª",
                                "- **æ¡ˆä¾‹ç¤ºä¾‹**: {cases_count} ä¸ª",
                                "- **NLPæ˜ å°„**: {mappings_count} ä¸ª"
                            ]
                        }
                    ]
                },
                "extraction_config": {
                    "concepts": {
                        "patterns": {
                            "process": {"keywords": ["å¤„ç†", "åŠ å·¥", "è¿‡ç¨‹"], "symbol": "åœ†å½¢"},
                            "entity": {"keywords": ["å¤–éƒ¨å®ä½“", "å®ä½“", "ç”¨æˆ·"], "symbol": "çŸ©å½¢"},
                            "data_store": {"keywords": ["æ•°æ®å­˜å‚¨", "æ•°æ®åº“"], "symbol": "å¹³è¡Œçº¿"},
                            "data_flow": {"keywords": ["æ•°æ®æµ", "ç®­å¤´"], "symbol": "ç®­å¤´"}
                        }
                    },
                    "rules": {
                        "hierarchy": {"keywords": ["å±‚æ¬¡", "åˆ†å±‚"], "description": "åˆ†å±‚ç»“æ„è§„åˆ™"},
                        "connection": {"keywords": ["è¿æ¥", "æµå‘"], "description": "è¿æ¥è§„åˆ™"}
                    },
                    "system_types": {
                        "ç”µå•†ç³»ç»Ÿ": ["ç”µå•†", "è®¢å•"],
                        "ç®¡ç†ç³»ç»Ÿ": ["ç®¡ç†", "ä¿¡æ¯ç³»ç»Ÿ"]
                    },
                    "case_keywords": {
                        "error": ["é”™è¯¯", "é—®é¢˜"],
                        "best_practice": ["æ­£ç¡®", "å»ºè®®"]
                    }
                }
            }
        }
    
    def get_format_name(self) -> str:
        """è·å–å½“å‰æ ¼å¼åç§°"""
        return self.format_name
    
    def get_available_formats(self) -> List[str]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„æ ¼å¼ç±»å‹"""
        if hasattr(self, 'templates') and self.templates:
            return list(self.templates.keys())
        return [self.format_type] if hasattr(self, 'format_type') else []
    
    def get_format_info(self, format_type: str) -> Dict:
        """è·å–æŒ‡å®šæ ¼å¼çš„ä¿¡æ¯"""
        if hasattr(self, 'templates') and self.templates:
            return self.templates.get(format_type, {})
        return self.template if format_type == self.format_type else {}
    
    def extract_knowledge(self, content: str, url: str = "", title: str = "") -> Dict:
        """æ ¹æ®é…ç½®æ–‡ä»¶æå–çŸ¥è¯†åº“æ•°æ®"""
        extracted_data = {}
        
        # ä»é…ç½®æ–‡ä»¶ä¸­è·å–çŸ¥è¯†åº“ç±»åˆ«
        knowledge_categories = self.template.get('json_structure', {}).get('knowledge_categories', [])
        extraction_config = self.template.get('extraction_config', {})
        
        # ä¸ºæ¯ä¸ªçŸ¥è¯†åº“ç±»åˆ«æå–æ•°æ®
        for category in knowledge_categories:
            category_key = category.get('key')
            if category_key:
                extracted_data[category_key] = self._extract_by_category(content, category_key, extraction_config, url, title)
        
        return extracted_data
    
    def _extract_by_category(self, content: str, category_key: str, extraction_config: Dict, url: str = "", title: str = "") -> List[Dict]:
        """æ ¹æ®é…ç½®æ–‡ä»¶é€šç”¨æå–æ–¹æ³•"""
        extracted_items = []
        
        if category_key == 'dfd_concepts':
            extracted_items = self._extract_concepts_from_config(content, extraction_config)
        elif category_key == 'dfd_rules':
            extracted_items = self._extract_rules_from_config(content, extraction_config)
        elif category_key == 'dfd_patterns':
            extracted_items = self._extract_patterns_from_config(content, extraction_config, url, title)
        elif category_key == 'dfd_cases':
            extracted_items = self._extract_cases_from_config(content, extraction_config)
        elif category_key == 'dfd_nlp_mappings':
            extracted_items = self._extract_nlp_mappings_from_config(content, extraction_config)
        
        return extracted_items
    
    def _extract_concepts_from_config(self, content: str, extraction_config: Dict) -> List[Dict]:
        """ä»é…ç½®æ–‡ä»¶æå–DFDæ¦‚å¿µå®šä¹‰"""
        concepts = []
        concept_patterns = extraction_config.get('concepts', {}).get('patterns', {})
        
        concept_id = 1
        for element_type, info in concept_patterns.items():
            keywords = info.get('keywords', [])
            symbol = info.get('symbol', '')
            
            for keyword in keywords:
                if keyword in content:
                    concepts.append({
                        'id': f"{element_type[:4]}-{concept_id:03d}",
                        'type': element_type,
                        'description': f"{keyword}ç›¸å…³çš„DFDå…ƒç´ å®šä¹‰",
                        'symbol': symbol,
                        'rules': [f"{keyword}çš„ä½¿ç”¨è§„åˆ™å’Œçº¦å®š"]
                    })
                    concept_id += 1
                    break
        
        return concepts
    
    def _extract_rules_from_config(self, content: str, extraction_config: Dict) -> List[Dict]:
        """ä»é…ç½®æ–‡ä»¶æå–DFDè§„åˆ™"""
        rules = []
        rule_config = extraction_config.get('rules', {})
        rule_id = 1
        
        for rule_category, rule_info in rule_config.items():
            keywords = rule_info.get('keywords', [])
            description = rule_info.get('description', '')
            
            if any(keyword in content for keyword in keywords):
                rules.append({
                    'id': f'{rule_category[:2]}-{rule_id:02d}',
                    'category': rule_category,
                    'description': description,
                    'condition': f'{rule_category}_condition',
                    'validation': f'check_{rule_category}_rules()'
                })
                rule_id += 1
        
        return rules
    
    def _extract_patterns_from_config(self, content: str, extraction_config: Dict, url: str = "", title: str = "") -> List[Dict]:
        """ä»é…ç½®æ–‡ä»¶æå–DFDæ¨¡å¼"""
        patterns = []
        system_types = extraction_config.get('system_types', {})
        
        # æ ¹æ®å†…å®¹æ¨æ–­ç³»ç»Ÿç±»å‹
        system_type = "é€šç”¨ç³»ç»Ÿ"
        for sys_name, keywords in system_types.items():
            if any(keyword in content for keyword in keywords):
                system_type = sys_name
                break
        
        if any(keyword in content for keyword in ["ç³»ç»Ÿ", "æµç¨‹", "å¤„ç†"]):
            patterns.append({
                'system': system_type,
                'level': 0,
                'processes': [{'id': 'P1', 'name': f'{system_type}æ ¸å¿ƒå¤„ç†'}],
                'entities': [{'id': 'E1', 'name': 'ç”¨æˆ·'}],
                'data_stores': [{'id': 'D1', 'name': 'æ•°æ®åº“'}],
                'flows': [{'from': 'E1', 'to': 'P1', 'data': 'è¾“å…¥æ•°æ®'}]
            })
        
        return patterns
    
    def _extract_cases_from_config(self, content: str, extraction_config: Dict) -> List[Dict]:
        """ä»é…ç½®æ–‡ä»¶æå–DFDæ¡ˆä¾‹"""
        cases = []
        case_keywords = extraction_config.get('case_keywords', {})
        case_id = 1
        
        # æ£€æµ‹é”™è¯¯æ¡ˆä¾‹å…³é”®è¯
        error_keywords = case_keywords.get('error', [])
        best_practice_keywords = case_keywords.get('best_practice', [])
        
        if any(keyword in content for keyword in error_keywords):
            cases.append({
                'id': f'case-err-{case_id:03d}',
                'type': 'error_case',
                'description': 'ä»ç½‘é¡µå†…å®¹ä¸­è¯†åˆ«çš„DFDç»˜åˆ¶é”™è¯¯æ¡ˆä¾‹',
                'incorrect': {'elements': ['é”™è¯¯çš„å…ƒç´ è¿æ¥'], 'flows': ['ä¸è§„èŒƒçš„æ•°æ®æµ']},
                'correct': {'elements': ['æ­£ç¡®çš„å…ƒç´ è¿æ¥'], 'flows': ['è§„èŒƒçš„æ•°æ®æµ']},
                'explanation': 'åŸºäºç½‘é¡µå†…å®¹æ€»ç»“çš„é”™è¯¯åŸå› å’Œæ”¹æ­£æ–¹æ³•'
            })
            case_id += 1
        
        if any(keyword in content for keyword in best_practice_keywords):
            cases.append({
                'id': f'case-best-{case_id:03d}',
                'type': 'best_practice',
                'description': 'ä»ç½‘é¡µå†…å®¹ä¸­æå–çš„DFDæœ€ä½³å®è·µ',
                'incorrect': {},
                'correct': {'elements': ['æ¨èçš„å…ƒç´ è®¾è®¡'], 'flows': ['æ ‡å‡†çš„æ•°æ®æµè®¾è®¡']},
                'explanation': 'åŸºäºç½‘é¡µå†…å®¹æ€»ç»“çš„æœ€ä½³å®è·µè¦ç‚¹'
            })
            case_id += 1
        
        return cases
    
    def _extract_nlp_mappings_from_config(self, content: str, extraction_config: Dict) -> List[Dict]:
        """ä»é…ç½®æ–‡ä»¶æå–DFD NLPæ˜ å°„"""
        mappings = []
        
        # åŸºäºå†…å®¹æ£€æµ‹å¸¸è§çš„NLPæ¨¡å¼
        if any(keyword in content for keyword in ['ç”¨æˆ·', 'ç³»ç»Ÿ', 'æ“ä½œ', 'å¤„ç†']):
            mappings.extend([
                {
                    'pattern': 'ç”¨æˆ· [action] ç³»ç»Ÿ',
                    'element_type': 'data_flow',
                    'name_template': '{ç”¨æˆ·}åˆ°{ç³»ç»Ÿ}çš„{action}',
                    'flow_template': '{action}è¯·æ±‚',
                    'action_mappings': {'æäº¤': 'è¾“å…¥', 'æŸ¥è¯¢': 'è¯·æ±‚', 'ä¿®æ”¹': 'æ›´æ–°'}
                },
                {
                    'pattern': 'ç³»ç»Ÿ [action] æ•°æ®åº“',
                    'element_type': 'data_flow',
                    'name_template': '{ç³»ç»Ÿ}å¯¹{æ•°æ®åº“}çš„{action}',
                    'flow_template': '{action}æ“ä½œ',
                    'action_mappings': {'å­˜å‚¨': 'å†™å…¥', 'è¯»å–': 'æŸ¥è¯¢', 'åˆ é™¤': 'ç§»é™¤'}
                }
            ])
        
        return mappings
    

    
    def generate_json_structure(self, extracted_data: Dict, url: str, title: str) -> Dict:
        """æ ¹æ®é…ç½®ç”ŸæˆJSONç»“æ„"""
        # æ„å»ºå…ƒæ•°æ®
        metadata = {
            "source_url": url,
            "source_title": title,
            "crawl_time": datetime.now().isoformat(),
            "extraction_method": "åŸºäºé…ç½®æ–‡ä»¶çš„è‡ªåŠ¨æå–",
            "topic": "DFD"
        }
        
        categories = self.template["json_structure"]["knowledge_categories"]
        
        # æ„å»ºJSONç»“æ„
        json_obj = {
            "metadata": metadata,
            "statistics": {}
        }
        
        # æ ¹æ®é…ç½®æ·»åŠ å„ä¸ªçŸ¥è¯†ç±»åˆ«
        for category in categories:
            key = category["key"]
            if key in extracted_data:  # ç›´æ¥åŒ¹é…å®Œæ•´çš„key
                json_obj[key] = extracted_data[key]
                json_obj["statistics"][f"{key.split('_')[-1]}_count"] = len(extracted_data[key])
            else:
                json_obj[key] = []
                json_obj["statistics"][f"{key.split('_')[-1]}_count"] = 0
        
        return json_obj
    
    def generate_markdown(self, extracted_data: Dict, metadata: Dict) -> str:
        """æ ¹æ®é…ç½®ç”ŸæˆMarkdownæ ¼å¼"""
        content_analysis = metadata.get('content_analysis', 'å†…å®¹åˆ†æç»“æœ')
        
        template = self.template["markdown_template"]
        md_lines = []
        
        # ç”Ÿæˆæ ‡é¢˜å’Œå…ƒæ•°æ®
        title_template = template["header"]["title"]
        md_lines.append(self._format_template(title_template, metadata))
        
        for meta_line in template["header"]["metadata"]:
            md_lines.append(self._format_template(meta_line, metadata))
        
        md_lines.append("")
        
        # ç”Ÿæˆå„ä¸ªéƒ¨åˆ†
        for section in template["sections"]:
            md_lines.append(section["title"])
            
            if "content" in section:
                if isinstance(section["content"], str):
                    md_lines.append(self._format_template(section["content"], {**metadata, "content_analysis": content_analysis}))
                elif isinstance(section["content"], list):
                    for line in section["content"]:
                        # ä»é…ç½®æ–‡ä»¶åŠ¨æ€è·å–çŸ¥è¯†åº“ç±»åˆ«
                        categories = self.template["json_structure"]["knowledge_categories"]
                        stats = {f"{category['key'].split('_')[-1]}_count": len(extracted_data.get(category['key'], [])) 
                                for category in categories}
                        md_lines.append(self._format_template(line, stats))
            
            if "description" in section:
                md_lines.append(section["description"])
            
            # å¤„ç†æ•°æ®é¡¹
            if "item_template" in section:
                section_key = section["title"].split("(")[-1].split(")")[0] if "(" in section["title"] else ""
                data_key = section_key if section_key in extracted_data else ""
                
                if data_key in extracted_data and extracted_data[data_key]:
                    for item in extracted_data[data_key]:
                        # ç”Ÿæˆé¡¹ç›®æ ‡é¢˜
                        header = self._format_template(section["item_template"]["header"], item)
                        md_lines.append(header)
                        
                        # ç”Ÿæˆé¡¹ç›®å­—æ®µ
                        for field_template in section["item_template"]["fields"]:
                            # å¤„ç†ç‰¹æ®Šå­—æ®µï¼ˆå¦‚æ•°ç»„è¿æ¥ï¼‰
                            item_data = item.copy()
                            if "rules_joined" in field_template and "rules" in item:
                                item_data["rules_joined"] = ", ".join(item["rules"])
                            if "processes_count" in field_template and "processes" in item:
                                item_data["processes_count"] = len(item["processes"])
                            if "entities_count" in field_template and "entities" in item:
                                item_data["entities_count"] = len(item["entities"])
                            if "data_stores_count" in field_template and "data_stores" in item:
                                item_data["data_stores_count"] = len(item["data_stores"])
                            if "flows_count" in field_template and "flows" in item:
                                item_data["flows_count"] = len(item["flows"])
                            
                            md_lines.append(self._format_template(field_template, item_data))
                        md_lines.append("")
                else:
                    md_lines.append(section["empty_message"])
            
            md_lines.append("")
        
        # ç”Ÿæˆé¡µè„š
        if "footer" in template:
            md_lines.append(template["footer"]["title"])
            for line in template["footer"]["content"]:
                md_lines.append(line)
        
        return "\n".join(md_lines)
    
    def _format_template(self, template: str, data: Dict) -> str:
        """æ ¼å¼åŒ–æ¨¡æ¿å­—ç¬¦ä¸²"""
        try:
            return template.format(**data)
        except KeyError as e:
            # å¦‚æœç¼ºå°‘æŸä¸ªé”®ï¼Œè¿”å›åŸå§‹æ¨¡æ¿
            return template
    
    def reload_templates(self):
        """é‡æ–°åŠ è½½æ¨¡æ¿é…ç½®"""
        templates = self._load_templates()
        if self.format_type in templates:
            self.template = templates[self.format_type]
        else:
            self.template = self._get_default_template()["dfd"]
    
    def add_format_template(self, format_type: str, template_config: Dict):
        """æ·»åŠ æ–°çš„æ ¼å¼æ¨¡æ¿"""
        templates = self._load_templates()
        templates[format_type] = template_config
        
        # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(templates, f, ensure_ascii=False, indent=2)
    
    def update_format_template(self, format_type: str, template_config: Dict):
        """æ›´æ–°ç°æœ‰æ ¼å¼æ¨¡æ¿"""
        templates = self._load_templates()
        if format_type not in templates:
            raise ValueError(f"æ ¼å¼ç±»å‹ä¸å­˜åœ¨: {format_type}")
        
        templates[format_type].update(template_config)
        
        # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(templates, f, ensure_ascii=False, indent=2)
    
    def save_knowledge_base(self, data: Dict, base_filename: str = None, output_dir: str = "shared_data/knowledge_base") -> Dict:
        """æ ¹æ®æ ¼å¼é…ç½®ä¿å­˜çŸ¥è¯†åº“æ•°æ®åˆ°ç‹¬ç«‹æ–‡ä»¶"""
        try:
            from datetime import datetime as _dt
            
            # ç”Ÿæˆæ–‡ä»¶åå‰ç¼€
            if not base_filename:
                timestamp = _dt.now().strftime('%Y%m%d_%H%M%S')
                base_filename = f"{self.format_type}_knowledge_{timestamp}"
            
            # åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
            kb_dir = Path(output_dir)
            kb_dir.mkdir(parents=True, exist_ok=True)
            
            saved_files = []
            
            # è·å–çŸ¥è¯†åˆ†ç±»é…ç½®
            knowledge_categories = self.template.get("json_structure", {}).get("knowledge_categories", [])
            
            # æ ¹æ®é…ç½®ä¿å­˜æ¯ä¸ªåˆ†ç±»çš„æ•°æ®
            for category in knowledge_categories:
                category_key = category["key"]
                category_name = category["name"]
                category_desc = category["description"]
                category_fields = category.get("fields", {})
                
                if category_key in data and data[category_key]:
                    # ç”Ÿæˆæ–‡ä»¶è·¯å¾„
                    file_path = kb_dir / f"{base_filename}_{category_key.replace('dfd_', '')}.json"
                    
                    # æ„å»ºæ•°æ®ç»“æ„
                    category_data = {
                        "table_name": category_key,
                        "description": category_desc,
                        "schema": self._generate_schema_from_fields(category_fields),
                        "data": data[category_key],
                        "metadata": data.get('metadata', {})
                    }
                    
                    # ä¿å­˜æ–‡ä»¶
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump(category_data, f, ensure_ascii=False, indent=2)
                    
                    saved_files.append(str(file_path))
            
            # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
            summary_file = kb_dir / f"{base_filename}_summary.json"
            summary_data = {
                "extraction_summary": {
                    "source_url": data.get('metadata', {}).get('source_url', ''),
                    "extraction_time": _dt.now().isoformat(),
                    "total_files_saved": len(saved_files),
                    "statistics": data.get('statistics', {})
                },
                "saved_files": saved_files,
                "knowledge_base_structure": {cat["key"]: cat["description"] for cat in knowledge_categories}
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            return {
                "success": True,
                "saved_files": saved_files,
                "summary_file": str(summary_file),
                "statistics": data.get('statistics', {})
            }
            
        except Exception as e:
            logger.error(f"ä¿å­˜çŸ¥è¯†åº“æ•°æ®å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _generate_schema_from_fields(self, fields: Dict) -> Dict:
        """æ ¹æ®å­—æ®µé…ç½®ç”Ÿæˆæ•°æ®åº“æ¨¡å¼"""
        schema = {}
        for field_name, field_type in fields.items():
            if field_type == "string":
                schema[field_name] = "text"
            elif field_type == "integer":
                schema[field_name] = "int"
            elif field_type == "array":
                schema[field_name] = "jsonb (æ•°ç»„)"
            elif field_type == "object":
                schema[field_name] = "jsonb (å¯¹è±¡)"
            else:
                schema[field_name] = f"text ({field_type})"
        return schema

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    processor = FormatProcessor()
    
    # æŸ¥çœ‹å¯ç”¨æ ¼å¼
    logger.info("å¯ç”¨æ ¼å¼: %s", processor.get_available_formats())
    
    # æŸ¥çœ‹DFDæ ¼å¼ä¿¡æ¯
    logger.info("DFDæ ¼å¼ä¿¡æ¯: %s", processor.get_format_info("dfd"))
    
    # æ¨¡æ‹Ÿæå–æ•°æ®
    sample_content = "è¿™æ˜¯å…³äºæ•°æ®æµå›¾çš„å†…å®¹ï¼ŒåŒ…å«å¤„ç†è¿‡ç¨‹ã€å¤–éƒ¨å®ä½“ã€æ•°æ®å­˜å‚¨ç­‰æ¦‚å¿µã€‚"
    extracted = processor.extract_knowledge(sample_content, "https://example.com", "æµ‹è¯•é¡µé¢")
    logger.info("æå–çš„æ•°æ®: %s", extracted)
    
    # æµ‹è¯•ç”ŸæˆJSONå’ŒMarkdown
    metadata = {
        "source_url": "https://example.com",
        "title": "æµ‹è¯•é¡µé¢",
        "crawl_time": datetime.now().isoformat(),
        "crawl_time_human": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "extraction_method": "åŸºäºé…ç½®æ–‡ä»¶çš„è‡ªåŠ¨æå–",
        "topic": "DFD",
        "content_analysis": "è¿™æ˜¯å†…å®¹åˆ†æç»“æœ"
    }
    
    json_result = processor.generate_json_structure(extracted, "https://example.com", "æµ‹è¯•é¡µé¢")
    logger.info("JSONç»“æ„: %s", json.dumps(json_result, ensure_ascii=False, indent=2))
    
    # æµ‹è¯•Markdownç”Ÿæˆ
    md_result = processor.generate_markdown(extracted, metadata)
    logger.info("Markdownç»“æœ:")
    logger.info(md_result)