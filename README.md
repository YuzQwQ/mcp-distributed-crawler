# MCPåˆ†å¸ƒå¼çˆ¬è™«ç³»ç»Ÿ

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.7+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg" alt="Status">
</p>

<p align="center">
  ä¼ä¸šçº§åˆ†å¸ƒå¼çˆ¬è™«ç³»ç»Ÿï¼Œé›†æˆDFDçŸ¥è¯†æ”¶é›†ã€æ™ºèƒ½ä»£ç†æ± ã€äººæ€§åŒ–è®¿é—®æ§åˆ¶ç­‰é«˜çº§åŠŸèƒ½
</p>

## ğŸš€ é¡¹ç›®ç‰¹è‰²

### âœ¨ æ ¸å¿ƒåŠŸèƒ½
- **ğŸ•·ï¸ åˆ†å¸ƒå¼çˆ¬è™«æ¶æ„** - æ”¯æŒå¤šèŠ‚ç‚¹å¹¶è¡Œçˆ¬å–
- **ğŸ“Š DFDçŸ¥è¯†æ”¶é›†** - æ™ºèƒ½ä¸šåŠ¡æµç¨‹åˆ†æä¸å¯è§†åŒ–
- **ğŸ”„ ä»£ç†æ± ç®¡ç†** - è‡ªåŠ¨ä»£ç†è½®æ¢ä¸éªŒè¯
- **ğŸ­ äººæ€§åŒ–è®¿é—®** - æ™ºèƒ½å»¶è¿Ÿæ§åˆ¶ï¼Œé¿å…è¢«å°
- **ğŸ“ˆ å®æ—¶ç›‘æ§** - Webç›‘æ§é¢æ¿å®æ—¶æŸ¥çœ‹çŠ¶æ€
- **ğŸ—ƒï¸ çŸ¥è¯†åº“ç³»ç»Ÿ** - ç»“æ„åŒ–çŸ¥è¯†ç®¡ç†ä¸æ£€ç´¢

### ğŸ¯ æŠ€æœ¯æ ˆ
- **åç«¯**: Python 3.7+, asyncio, FastAPI
- **æ•°æ®åº“**: Redis, SQLite
- **çˆ¬è™«**: Playwright, Selenium, Requests
- **ä»£ç†**: SOCKS5, HTTPä»£ç†, Torç½‘ç»œ
- **ç›‘æ§**: å®æ—¶Webä»ªè¡¨æ¿
- **éƒ¨ç½²**: Dockeræ”¯æŒï¼ˆå³å°†æ¨å‡ºï¼‰

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/YuzQwQ/mcp-distributed-crawler.git
cd mcp-distributed-crawler

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. å¯åŠ¨Redis
```bash
# Windows
redis-server.exe redis.windows.conf

# Linux/Mac
redis-server
```

### 3. å¯åŠ¨ç³»ç»Ÿ
```bash
# ä¸€é”®å¯åŠ¨å®Œæ•´ç³»ç»Ÿ
python start_distributed_system.py start --workers 3

# è®¿é—®ç›‘æ§é¢æ¿
# http://localhost:8080
```

### 4. åŠŸèƒ½æµ‹è¯•
```bash
# æµ‹è¯•DFDçŸ¥è¯†æ”¶é›†
python enhanced_dfd_collector.py

# æµ‹è¯•çŸ¥è¯†åº“æ•´ç†
python knowledge_organizer.py
```

## ğŸ“Š ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä»»åŠ¡è°ƒåº¦å™¨     â”‚    â”‚   å·¥ä½œèŠ‚ç‚¹1     â”‚    â”‚   å·¥ä½œèŠ‚ç‚¹2     â”‚
â”‚  task_scheduler  â”‚â”€â”€â”€â”€â”‚  worker_node    â”‚â”€â”€â”€â”€â”‚  worker_node    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   ç»“æœæ”¶é›†å™¨     â”‚    â”‚   ç›‘æ§ç³»ç»Ÿ       â”‚    â”‚   ä»£ç†æ±         â”‚
    â”‚ result_collectorâ”‚    â”‚  monitoring     â”‚    â”‚ proxy_pool      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ æ ¸å¿ƒæ¨¡å—

### 1. åˆ†å¸ƒå¼çˆ¬è™«ç³»ç»Ÿ
- **ä»»åŠ¡è°ƒåº¦å™¨** - æ™ºèƒ½ä»»åŠ¡åˆ†é…
- **å·¥ä½œèŠ‚ç‚¹** - å¹¶è¡Œçˆ¬å–å¤„ç†
- **ç»“æœæ”¶é›†å™¨** - ç»Ÿä¸€æ•°æ®æ”¶é›†
- **ç›‘æ§ç³»ç»Ÿ** - å®æ—¶çŠ¶æ€ç›‘æ§

### 2. DFDçŸ¥è¯†æ”¶é›†ç³»ç»Ÿ
- **çŸ¥è¯†æ”¶é›†** - è‡ªåŠ¨æ”¶é›†ä¸šåŠ¡æµç¨‹çŸ¥è¯†
- **çŸ¥è¯†åˆ†æ** - æ™ºèƒ½åˆ†æä¸éªŒè¯
- **çŸ¥è¯†å¯è§†åŒ–** - ç”Ÿæˆå›¾è¡¨ä¸æŠ¥å‘Š
- **çŸ¥è¯†å­˜å‚¨** - ç»“æ„åŒ–çŸ¥è¯†ç®¡ç†

### 3. ä»£ç†æ± ç®¡ç†ç³»ç»Ÿ
- **ä»£ç†éªŒè¯** - å®æ—¶ä»£ç†å¯ç”¨æ€§æ£€æµ‹
- **ä»£ç†è½®æ¢** - æ™ºèƒ½ä»£ç†é€‰æ‹©
- **ä»£ç†ç›‘æ§** - ä»£ç†çŠ¶æ€å®æ—¶ç›‘æ§
- **ä»£ç†è¡¥å……** - è‡ªåŠ¨ä»£ç†å‘ç°

### 4. äººæ€§åŒ–è®¿é—®ç³»ç»Ÿ
- **æ™ºèƒ½å»¶è¿Ÿ** - æ¨¡æ‹Ÿäººç±»è®¿é—®è¡Œä¸º
- **User-Agentè½®æ¢** - é¿å…è¢«è¯†åˆ«ä¸ºçˆ¬è™«
- **è¯·æ±‚éšæœºåŒ–** - é™ä½è¢«å°é£é™©
- **å¼‚å¸¸å¤„ç†** - æ™ºèƒ½é”™è¯¯æ¢å¤

## ğŸ“‹ é¡¹ç›®ç»“æ„

```
mcp-distributed-crawler/
â”œâ”€â”€ ğŸ“ distributed/           # åˆ†å¸ƒå¼ç³»ç»Ÿæ ¸å¿ƒç»„ä»¶
â”‚   â”œâ”€â”€ task_scheduler.py   # ä»»åŠ¡è°ƒåº¦å™¨
â”‚   â”œâ”€â”€ worker_node.py      # å·¥ä½œèŠ‚ç‚¹
â”‚   â”œâ”€â”€ result_collector.py # ç»“æœæ”¶é›†å™¨
â”‚   â””â”€â”€ monitoring.py       # ç›‘æ§ç³»ç»Ÿ
â”œâ”€â”€ ğŸ“ knowledge_base/      # çŸ¥è¯†åº“ç³»ç»Ÿ
â”œâ”€â”€ ğŸ“ utils/               # å·¥å…·åº“
â”‚   â”œâ”€â”€ proxy_pool.py       # ä»£ç†æ± ç®¡ç†
â”‚   â”œâ”€â”€ stealth_crawler.py  # éšå½¢çˆ¬è™«
â”‚   â””â”€â”€ web_deduplication.py # å»é‡ç³»ç»Ÿ
â”œâ”€â”€ ğŸ“ docs/                # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ ğŸ“ tests/               # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ ğŸ“ scripts/             # è„šæœ¬å·¥å…·
â””â”€â”€ ğŸ“ knowledge_base/      # çŸ¥è¯†åº“å­˜å‚¨
```

## ğŸ® ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€çˆ¬è™«ä»»åŠ¡
```python
# æäº¤çˆ¬è™«ä»»åŠ¡
from distributed.task_queue import TaskQueue

queue = TaskQueue()
task = {
    "url": "https://example.com",
    "method": "GET",
    "callback": "parse_data"
}
queue.add_task(task)
```

### DFDçŸ¥è¯†æ”¶é›†
```python
# æ”¶é›†ä¸šåŠ¡æµç¨‹çŸ¥è¯†
from enhanced_dfd_collector import EnhancedDFDKnowledgeCollector

collector = EnhancedDFDKnowledgeCollector()
result = collector.collect_knowledge("ç”µå•†è®¢å•å¤„ç†æµç¨‹")
```

### ä»£ç†æ± ä½¿ç”¨
```python
# è·å–å¯ç”¨ä»£ç†
from utils.proxy_pool import ProxyPool

pool = ProxyPool()
proxy = pool.get_proxy()
```

## ğŸ§ª æµ‹è¯•

### è¿è¡Œæ‰€æœ‰æµ‹è¯•
```bash
python test_distributed_system.py
```

### è¿è¡Œç‰¹å®šæµ‹è¯•
```bash
# æµ‹è¯•DFDæ”¶é›†
python test_dfd_collection.py

# æµ‹è¯•ä»£ç†æ± 
python test_proxy_pool.py

# æµ‹è¯•äººæ€§åŒ–è®¿é—®
python test_humanized_access.py
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| å¹¶å‘èŠ‚ç‚¹ | æ”¯æŒ1-100ä¸ª |
| ä»»åŠ¡å¤„ç†é€Ÿåº¦ | 1000+ä»»åŠ¡/åˆ†é’Ÿ |
| ä»£ç†æ± è§„æ¨¡ | 1000+ä»£ç† |
| æˆåŠŸç‡ | 95%+ |
| çŸ¥è¯†æ”¶é›†å‡†ç¡®ç‡ | 100% |

## ğŸ›¡ï¸ å®‰å…¨ç‰¹æ€§

- **è¯·æ±‚åŠ å¯†** - ä¿æŠ¤æ•æ„Ÿæ•°æ®
- **è®¿é—®æ§åˆ¶** - æƒé™ç®¡ç†
- **æ—¥å¿—å®¡è®¡** - å®Œæ•´æ“ä½œè®°å½•
- **å¼‚å¸¸ç›‘æ§** - å®æ—¶å¼‚å¸¸æ£€æµ‹

## ğŸ“š æ–‡æ¡£

- [ğŸ“– å®Œæ•´éƒ¨ç½²æŒ‡å—](GITHUB_PUSH_GUIDE.md)
- [ğŸ”§ é…ç½®è¯´æ˜](docs/CONFIG_GUIDE.md)
- [ğŸ¯ ä½¿ç”¨æ•™ç¨‹](HUMANIZED_ACCESS_GUIDE.md)
- [ğŸ“Š ç³»ç»Ÿæ¶æ„](docs/distributed_crawler_architecture.md)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

### è´¡çŒ®æŒ‡å—
1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ **MIT** è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸŒŸ Starå†å²

[![Star History Chart](https://api.star-history.com/svg?repos=YuzQwQ/mcp-distributed-crawler&type=Date)](https://star-history.com/#YuzQwQ/mcp-distributed-crawler&Date)

## ğŸ“ è”ç³»æˆ‘ä»¬

- **Issues**: [GitHub Issues](https://github.com/YuzQwQ/mcp-distributed-crawler/issues)
- **Discussions**: [GitHub Discussions](https://github.com/YuzQwQ/mcp-distributed-crawler/discussions)

---

<p align="center">
  <b>ğŸš€ è®©æ•°æ®é‡‡é›†å˜å¾—æ›´æ™ºèƒ½ã€æ›´å®‰å…¨ã€æ›´é«˜æ•ˆï¼</b>
</p>