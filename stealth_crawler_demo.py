#!/usr/bin/env python3
"""Stealthçˆ¬è™«ç³»ç»Ÿæ¼”ç¤ºè„šæœ¬

å±•ç¤ºPlaywright + stealthååçˆ¬è™«ç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½ï¼š
- åŸºç¡€stealthçˆ¬å–
- ä»£ç†æ± é›†æˆ
- æ‰¹é‡å¹¶å‘çˆ¬å–
- åæ£€æµ‹ç­–ç•¥
- æ™ºèƒ½é‡è¯•æœºåˆ¶
"""

import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥ç»„ä»¶
try:
    from utils.stealth_crawler import StealthCrawler, create_stealth_crawler, stealth_crawl
    from utils.playwright_manager import PlaywrightManager, create_playwright_manager
    from utils.proxy_pool import ProxyPool
    STEALTH_AVAILABLE = True
except ImportError as e:
    logger.error(f"å¯¼å…¥Stealthçˆ¬è™«ç»„ä»¶å¤±è´¥: {e}")
    STEALTH_AVAILABLE = False

class StealthCrawlerDemo:
    """Stealthçˆ¬è™«æ¼”ç¤ºå™¨"""
    
    def __init__(self):
        self.demo_urls = {
            "basic_test": [
                "https://httpbin.org/user-agent",
                "https://httpbin.org/headers",
                "https://httpbin.org/ip"
            ],
            "detection_test": [
                "https://bot.sannysoft.com/",
                "https://intoli.com/blog/not-possible-to-block-chrome-headless/chrome-headless-test.html"
            ],
            "real_world": [
                "https://quotes.toscrape.com/",
                "https://books.toscrape.com/",
                "https://httpbin.org/delay/2"
            ]
        }
        
    async def run_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        if not STEALTH_AVAILABLE:
            print("âŒ Stealthçˆ¬è™«ç»„ä»¶ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install playwright playwright-stealth")
            return
            
        print("ğŸš€ Stealthçˆ¬è™«ç³»ç»Ÿæ¼”ç¤ºå¼€å§‹")
        print("=" * 60)
        
        # æ¼”ç¤ºé¡¹ç›®
        demos = [
            ("åŸºç¡€Stealthçˆ¬å–", self.demo_basic_stealth),
            ("æ‰¹é‡å¹¶å‘çˆ¬å–", self.demo_batch_crawling),
            ("åæ£€æµ‹åŠŸèƒ½", self.demo_anti_detection),
            ("ä»£ç†é›†æˆ", self.demo_proxy_integration),
            ("æ™ºèƒ½é‡è¯•æœºåˆ¶", self.demo_smart_retry),
            ("å®é™…åº”ç”¨åœºæ™¯", self.demo_real_world_usage)
        ]
        
        for demo_name, demo_func in demos:
            print(f"\nğŸ“‹ {demo_name}")
            print("-" * 40)
            try:
                await demo_func()
                print(f"âœ… {demo_name} æ¼”ç¤ºå®Œæˆ")
            except Exception as e:
                print(f"âŒ {demo_name} æ¼”ç¤ºå¤±è´¥: {e}")
                logger.error(f"æ¼”ç¤º {demo_name} å¤±è´¥: {e}")
                
        print("\nğŸ‰ Stealthçˆ¬è™«ç³»ç»Ÿæ¼”ç¤ºç»“æŸ")
        
    async def demo_basic_stealth(self):
        """æ¼”ç¤ºåŸºç¡€stealthçˆ¬å–"""
        config = {
            "playwright": {
                "browser_type": "chromium",
                "headless": True,
                "enable_stealth": True,
                "use_proxy_pool": False
            },
            "max_retries": 2
        }
        
        print("ğŸ” æµ‹è¯•åŸºç¡€stealthçˆ¬å–åŠŸèƒ½...")
        
        # å•ä¸ªURLçˆ¬å–
        result = await stealth_crawl("https://httpbin.org/user-agent", config)
        
        if result.success:
            print(f"âœ… æˆåŠŸçˆ¬å–: {result.url}")
            print(f"   çŠ¶æ€ç : {result.status_code}")
            print(f"   å†…å®¹é•¿åº¦: {len(result.content) if result.content else 0} å­—ç¬¦")
            print(f"   å“åº”æ—¶é—´: {result.response_time:.2f}ç§’")
            print(f"   Stealthåº”ç”¨: {'æ˜¯' if result.stealth_applied else 'å¦'}")
            
            # è§£æUser-Agentä¿¡æ¯
            if result.content:
                try:
                    import json
                    data = json.loads(result.content)
                    user_agent = data.get('user-agent', '')
                    print(f"   User-Agent: {user_agent[:80]}...")
                except:
                    pass
        else:
            print(f"âŒ çˆ¬å–å¤±è´¥: {result.error}")
            
    async def demo_batch_crawling(self):
        """æ¼”ç¤ºæ‰¹é‡å¹¶å‘çˆ¬å–"""
        config = {
            "playwright": {
                "browser_type": "chromium",
                "headless": True,
                "enable_stealth": True,
                "use_proxy_pool": False
            },
            "concurrent_limit": 3,
            "max_retries": 1
        }
        
        print("ğŸ”„ æµ‹è¯•æ‰¹é‡å¹¶å‘çˆ¬å–åŠŸèƒ½...")
        
        # æ‰¹é‡çˆ¬å–
        start_time = asyncio.get_event_loop().time()
        results = await stealth_crawl(self.demo_urls["basic_test"], config)
        end_time = asyncio.get_event_loop().time()
        
        successful_count = sum(1 for r in results if r.success)
        total_time = end_time - start_time
        
        print(f"âœ… æ‰¹é‡çˆ¬å–å®Œæˆ:")
        print(f"   æ€»URLæ•°: {len(results)}")
        print(f"   æˆåŠŸæ•°: {successful_count}")
        print(f"   æˆåŠŸç‡: {(successful_count/len(results)*100):.1f}%")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   å¹³å‡é€Ÿåº¦: {len(results)/total_time:.2f} URL/ç§’")
        
        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        for i, result in enumerate(results, 1):
            status = "âœ…" if result.success else "âŒ"
            print(f"   {i}. {status} {result.url} ({result.status_code if result.success else result.error})")
            
    async def demo_anti_detection(self):
        """æ¼”ç¤ºåæ£€æµ‹åŠŸèƒ½"""
        config = {
            "playwright": {
                "browser_type": "chromium",
                "headless": True,
                "enable_stealth": True,
                "use_proxy_pool": False,
                "anti_detection": {
                    "random_user_agent": True,
                    "random_viewport": True,
                    "block_webrtc": True,
                    "block_canvas_fingerprint": True
                }
            },
            "max_retries": 1
        }
        
        print("ğŸ›¡ï¸ æµ‹è¯•åæ£€æµ‹åŠŸèƒ½...")
        
        # æµ‹è¯•åæ£€æµ‹URL
        test_url = "https://bot.sannysoft.com/"
        
        try:
            result = await stealth_crawl(test_url, config, timeout=15000)
            
            if result.success:
                print(f"âœ… åæ£€æµ‹æµ‹è¯•æˆåŠŸ:")
                print(f"   URL: {result.url}")
                print(f"   çŠ¶æ€ç : {result.status_code}")
                print(f"   å“åº”æ—¶é—´: {result.response_time:.2f}ç§’")
                print(f"   Stealthåº”ç”¨: {'æ˜¯' if result.stealth_applied else 'å¦'}")
                
                # åˆ†æé¡µé¢å†…å®¹ä¸­çš„æ£€æµ‹ç»“æœ
                if result.content and len(result.content) > 100:
                    print(f"   é¡µé¢å†…å®¹é•¿åº¦: {len(result.content)} å­—ç¬¦")
                    print("   ğŸ” é¡µé¢æˆåŠŸåŠ è½½ï¼Œå¯èƒ½ç»•è¿‡äº†éƒ¨åˆ†æ£€æµ‹")
                else:
                    print("   âš ï¸ é¡µé¢å†…å®¹è¾ƒå°‘ï¼Œå¯èƒ½è¢«æ£€æµ‹åˆ°")
            else:
                print(f"âŒ åæ£€æµ‹æµ‹è¯•å¤±è´¥: {result.error}")
                
        except Exception as e:
            print(f"âš ï¸ åæ£€æµ‹æµ‹è¯•å¼‚å¸¸: {e}")
            
    async def demo_proxy_integration(self):
        """æ¼”ç¤ºä»£ç†é›†æˆ"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç†æ–‡ä»¶
        proxy_file = Path("proxy_list.txt")
        if not proxy_file.exists():
            print("âš ï¸ æœªæ‰¾åˆ°ä»£ç†æ–‡ä»¶ proxy_list.txtï¼Œè·³è¿‡ä»£ç†æ¼”ç¤º")
            print("   æç¤º: åˆ›å»º proxy_list.txt æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªä»£ç†åœ°å€ (æ ¼å¼: ip:port)")
            return
            
        proxy_config = {
            "use_free_proxies": False,
            "use_local_proxies": True,
            "local_config": {
                "proxy_file": "proxy_list.txt"
            }
        }
        
        config = {
            "playwright": {
                "browser_type": "chromium",
                "headless": True,
                "enable_stealth": True,
                "use_proxy_pool": True,
                "proxy_rotation_interval": 2
            },
            "max_retries": 1
        }
        
        print("ğŸŒ æµ‹è¯•ä»£ç†é›†æˆåŠŸèƒ½...")
        
        try:
            async with create_stealth_crawler(config, proxy_config) as crawler:
                # æµ‹è¯•å¤šä¸ªURLä»¥è§¦å‘ä»£ç†è½®æ¢
                results = await crawler.crawl_urls(self.demo_urls["basic_test"][:2])
                
                stats = crawler.get_stats()
                
                print(f"âœ… ä»£ç†é›†æˆæµ‹è¯•å®Œæˆ:")
                print(f"   çˆ¬å–ç»“æœæ•°: {len(results)}")
                print(f"   ä»£ç†åˆ‡æ¢æ¬¡æ•°: {stats.get('playwright', {}).get('proxy_switches', 0)}")
                print(f"   æˆåŠŸç‡: {(sum(1 for r in results if r.success)/len(results)*100):.1f}%")
                
                for i, result in enumerate(results, 1):
                    status = "âœ…" if result.success else "âŒ"
                    proxy_info = f" (ä»£ç†: {result.proxy_used})" if result.proxy_used else ""
                    print(f"   {i}. {status} {result.url}{proxy_info}")
                    
        except Exception as e:
            print(f"âŒ ä»£ç†é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            
    async def demo_smart_retry(self):
        """æ¼”ç¤ºæ™ºèƒ½é‡è¯•æœºåˆ¶"""
        config = {
            "playwright": {
                "browser_type": "chromium",
                "headless": True,
                "enable_stealth": True,
                "use_proxy_pool": False
            },
            "max_retries": 3,
            "retry_delay": 1,
            "use_fallback": True
        }
        
        print("ğŸ”„ æµ‹è¯•æ™ºèƒ½é‡è¯•æœºåˆ¶...")
        
        # æµ‹è¯•ä¸€ä¸ªå¯èƒ½å¤±è´¥çš„URL
        test_urls = [
            "https://httpbin.org/status/500",  # æœåŠ¡å™¨é”™è¯¯
            "https://httpbin.org/delay/10",    # è¶…æ—¶æµ‹è¯•
            "https://nonexistent-domain-12345.com"  # ä¸å­˜åœ¨çš„åŸŸå
        ]
        
        for url in test_urls:
            print(f"\n   æµ‹è¯•URL: {url}")
            try:
                result = await stealth_crawl(url, config, timeout=5000)
                
                print(f"   ç»“æœ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
                print(f"   é‡è¯•æ¬¡æ•°: {result.retry_count}")
                print(f"   å“åº”æ—¶é—´: {result.response_time:.2f}ç§’")
                if result.error:
                    print(f"   é”™è¯¯ä¿¡æ¯: {result.error[:100]}...")
                    
            except Exception as e:
                print(f"   å¼‚å¸¸: {e}")
                
    async def demo_real_world_usage(self):
        """æ¼”ç¤ºå®é™…åº”ç”¨åœºæ™¯"""
        config = {
            "playwright": {
                "browser_type": "chromium",
                "headless": True,
                "enable_stealth": True,
                "use_proxy_pool": False,
                "page_timeout": 15000,
                "navigation_timeout": 15000
            },
            "concurrent_limit": 2,
            "max_retries": 2
        }
        
        print("ğŸŒ æµ‹è¯•å®é™…åº”ç”¨åœºæ™¯...")
        
        # çˆ¬å–å®é™…ç½‘ç«™
        results = await stealth_crawl(self.demo_urls["real_world"], config)
        
        successful_count = sum(1 for r in results if r.success)
        
        print(f"âœ… å®é™…åº”ç”¨æµ‹è¯•å®Œæˆ:")
        print(f"   æµ‹è¯•ç½‘ç«™æ•°: {len(results)}")
        print(f"   æˆåŠŸçˆ¬å–: {successful_count}")
        print(f"   æˆåŠŸç‡: {(successful_count/len(results)*100):.1f}%")
        
        for i, result in enumerate(results, 1):
            status = "âœ…" if result.success else "âŒ"
            print(f"   {i}. {status} {result.url}")
            if result.success:
                print(f"      çŠ¶æ€ç : {result.status_code}")
                print(f"      å†…å®¹é•¿åº¦: {len(result.content) if result.content else 0} å­—ç¬¦")
                print(f"      å“åº”æ—¶é—´: {result.response_time:.2f}ç§’")
                
                # ç®€å•å†…å®¹åˆ†æ
                if result.content:
                    content_lower = result.content.lower()
                    if 'quotes' in result.url and 'quote' in content_lower:
                        print(f"      ğŸ“ æ£€æµ‹åˆ°å¼•ç”¨å†…å®¹")
                    elif 'books' in result.url and 'book' in content_lower:
                        print(f"      ğŸ“š æ£€æµ‹åˆ°å›¾ä¹¦å†…å®¹")
                    elif 'httpbin' in result.url:
                        print(f"      ğŸ”§ APIæµ‹è¯•å“åº”")
            else:
                print(f"      é”™è¯¯: {result.error}")
                
async def main():
    """ä¸»å‡½æ•°"""
    demo = StealthCrawlerDemo()
    await demo.run_demo()
    
if __name__ == "__main__":
    asyncio.run(main())