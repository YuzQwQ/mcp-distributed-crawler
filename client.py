import asyncio # è®©ä»£ç æ”¯æŒå¼‚æ­¥æ“ä½œ
import os
from openai import OpenAI
from dotenv import load_dotenv
from contextlib import AsyncExitStack # èµ„æºç®¡ç†ï¼ˆç¡®ä¿å®¢æˆ·ç«¯å…³é—­æ—¶é‡Šæ”¾èµ„æºï¼‰

# åŠ è½½ .env æ–‡ä»¶ï¼Œç¡®ä¿ API Key å—åˆ°ä¿æŠ¤
load_dotenv()

class MCPClient:
    def __init__(self):

        """åˆå§‹åŒ– MCP å®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()  # åˆ›å»ºèµ„æºç®¡ç†å™¨
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  # è¯»å– OpenAI API Key
        self.base_url = os.getenv("BASE_URL")  # è¯»å– BASE YRL
        self.model = os.getenv("MODEL")  # è¯»å– model

        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")

        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)
    # async def connect_to_mock_server(self):
    #     """æ¨¡æ‹Ÿ MCP æœåŠ¡å™¨çš„è¿æ¥ï¼ˆæš‚ä¸è¿æ¥çœŸå®æœåŠ¡å™¨ï¼‰"""
    #     print("âœ… MCP å®¢æˆ·ç«¯å·²åˆå§‹åŒ–ï¼Œä½†æœªè¿æ¥åˆ°æœåŠ¡å™¨")

    async def process_query(self,query: str) -> str:
        """è°ƒç”¨ OpenAI API å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        messages = [{"role":"system","content":"ä½ æ˜¯ä¸€ä¸ªçŒ«å¨˜ï¼Œå¸®åŠ©ç”¨æˆ·å›ç­”é—®é¢˜ï¼Œå¤šç”¨â€œå–µâ€å½“è¯­æ°”è¯ã€‚"}
                   ,{"role":"user","content":query}]
        try:
            # è°ƒç”¨ OpenAI API
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.7
                )
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âš ï¸ è°ƒç”¨ OpenAI API æ—¶å‡ºé”™: {str(e)}"


    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\nğŸ¤– MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")

        while True:  # æ— é™å¾ªç¯ï¼Œç›´åˆ°ç”¨æˆ·è¾“å…¥ â€˜quitâ€™
            try:
                query = input("\nä½ : ").strip()  # è®©ç”¨æˆ·è¾“å…¥é—®é¢˜
                if query.lower() == 'quit':  # å¦‚æœç”¨æˆ·è¾“å…¥ quitï¼Œé€€å‡ºå¾ªç¯
                    break

                response = await self.process_query(query)  # å‘é€ç”¨æˆ·è¾“å…¥åˆ° OpenAI
                print(f"\nğŸ¤– OpenAIï¼š{response}")

            except Exception as e:  # å‘ç”Ÿé”™è¯¯æ—¶æ•è·å¼‚å¸¸
                print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose()  # å…³é—­èµ„æºç®¡ç†å™¨

async def main():
    client = MCPClient()  # åˆ›å»º MCP å®¢æˆ·ç«¯
    try:
        # await client.connect_to_mock_server()  # è¿æ¥ï¼ˆæ¨¡æ‹Ÿï¼‰æœåŠ¡å™¨
        await client.chat_loop()  # è¿›å…¥èŠå¤©å¾ªç¯
    finally:
        await client.cleanup()  # ç¡®ä¿é€€å‡ºæ—¶æ¸…ç†èµ„æº

if __name__ == "__main__":
    asyncio.run(main())
