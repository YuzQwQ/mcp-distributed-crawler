#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘ç«™çˆ¬å–æµ‹è¯•è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨MCPçˆ¬è™«ç³»ç»Ÿè¿›è¡Œç½‘ç«™å†…å®¹æŠ“å–
"""

import asyncio
import sys
from client import MCPClient

async def test_website_crawling():
    """æµ‹è¯•ç½‘ç«™çˆ¬å–åŠŸèƒ½"""
    client = MCPClient()
    
    try:
        # è¿æ¥åˆ°MCPæœåŠ¡å™¨
        print("ğŸ”— æ­£åœ¨è¿æ¥åˆ°MCPæœåŠ¡å™¨...")
        await client.connect_to_server("server.py")
        print("âœ… å·²æˆåŠŸè¿æ¥åˆ°MCPæœåŠ¡å™¨")
        
        # æµ‹è¯•ç½‘ç«™åˆ—è¡¨
        test_websites = [
            "https://httpbin.org/html",  # ç®€å•çš„HTMLæµ‹è¯•é¡µé¢
            "https://example.com",       # ç»å…¸æµ‹è¯•ç½‘ç«™
            "https://httpbin.org/json",  # JSONå“åº”æµ‹è¯•
        ]
        
        print("\nğŸ§ª å¼€å§‹ç½‘ç«™çˆ¬å–æµ‹è¯•...")
        
        for i, url in enumerate(test_websites, 1):
            print(f"\nğŸ“„ æµ‹è¯• {i}/{len(test_websites)}: {url}")
            print("-" * 60)
            
            # æ„é€ çˆ¬å–è¯·æ±‚
            query = f"è¯·çˆ¬å–å¹¶åˆ†æè¿™ä¸ªç½‘é¡µçš„å†…å®¹: {url}"
            
            try:
                # æ‰§è¡Œçˆ¬å–
                response = await client.process_query(query)
                print(f"âœ… çˆ¬å–æˆåŠŸ!")
                print(f"ğŸ“Š åˆ†æç»“æœ:\n{response[:500]}..." if len(response) > 500 else f"ğŸ“Š åˆ†æç»“æœ:\n{response}")
                
            except Exception as e:
                print(f"âŒ çˆ¬å–å¤±è´¥: {str(e)}")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
            if i < len(test_websites):
                print("â³ ç­‰å¾…3ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
                await asyncio.sleep(3)
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        
        # æµ‹è¯•æœç´¢åŠŸèƒ½
        print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
        search_query = "è¯·æœç´¢å…³äºPythonçˆ¬è™«çš„ç›¸å…³ä¿¡æ¯"
        try:
            search_response = await client.process_query(search_query)
            print(f"âœ… æœç´¢æˆåŠŸ!")
            print(f"ğŸ“Š æœç´¢ç»“æœ:\n{search_response[:500]}..." if len(search_response) > 500 else f"ğŸ“Š æœç´¢ç»“æœ:\n{search_response}")
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    
    finally:
        # æ¸…ç†èµ„æº
        await client.cleanup()
        print("\nğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ç½‘ç«™çˆ¬å–æµ‹è¯•")
    print("=" * 60)
    
    await test_website_crawling()
    
    print("\n" + "=" * 60)
    print("ğŸ æµ‹è¯•ç»“æŸ")

if __name__ == "__main__":
    asyncio.run(main())